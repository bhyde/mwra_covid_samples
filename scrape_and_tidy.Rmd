---
title: "MWRA's data on RNA fragments of SARS-CoV-2 in the waste water."
output:
  html_document:
    code_folding: hide
---

# Disclaimer
Warning - amateur at work.  I know little to nothing about: virology, epidemology, RStudio, sewage treatment and so many other things.

# Introduction
Scroll to the bottom to see the charts.  Most of this is the R code to load, scrape, clean, normalize the data.

The Massachusetts Water Resources Agency or MWRA has a large sewage treatment facility (Deer Island) that handles the sewage generated by much of the area around Boston.  The inflow to this comes from two regions, north and south.  The Charles river divides these two, though the city of boston is in the Northern region.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Install packages we use below, if necessary
for(pkg in c("tidyverse", "urltools", "rvest", "here",
             "feasts", "pdftools", "gridExtra")){
  if (!(pkg %in% installed.packages())) { install.packages(pkg)}}
library(tidyverse)
library(feasts)
library(urltools)
library(rvest)
library(here)
library(gt)
library(lubridate)
library(ggplot2)
library(scales)
library(gridExtra)
library(pdftools)
```
## Fetch the pdf of data.
The MWRA releases fresh data about once a week (["http://www.mwra.com/biobot/biobotdata.htm"](here)).  Sometime twice a week.  The data released usually a few days old.
```{r fetch_data}
# The html page links to a pdf, who's url changes.  That contains a table of data.
base_url = "http://www.mwra.com/biobot/"
latest_report_url = paste0(base_url, "biobotdata.htm") 
latest_html = (latest_report_url %>% read_html())
latest_pdf_url = ( latest_html
                   %>% html_node('a[href*="NSdata"]')
                   %>% html_attr('href')
                   %>% paste0(base_url, .) )
if ( ! file.exists(here("data", basename(latest_pdf_url))) ){
  download.file(url=latest_pdf_url, 
                destfile=here("data", basename(latest_pdf_url)))
  file.remove(here("data", "mwra_samples.pdf"))
  file.symlink(
     basename(latest_pdf_url),
     here("data", "mwra_samples.pdf")) }
```
## Extract and tidy that data into a tibble: <date> <northern-sample> <southern-sample>
```{r extract_data}
# use pdf tools to extract the data.
pdf <- pdf_text(here("data", "mwra_samples.pdf"))

lines <- (read_lines(reduce(pdf[1:length(pdf)], paste0))    # pdf is N pages, merge them, break into lines
          %>% as_tibble                                     # enter the tidyverse
          %>% filter(grepl('^ *\\d+/\\d+/\\d+ ',value))     # retain only the lines reporting samples on a date
          %>% mutate(value=str_trim(value, side = "both"))  # we will split on space, but discard edge spaces
          %>% mutate(value=str_replace(value, "               ", "            NA"))  # too clever way to fill
          %>% mutate(value=str_replace(value, "(\\d)    (\\d)", "\\1 NA \\2"))       # in the empty celsl with
          %>% mutate(value=str_replace(value, "^    (\\d)", "NA \\1"))               # NA.
          %>% mutate(value=str_squish(value))
          %>% separate(value, sep=" ", into=c("date","northern", "southern", "a", "b", "c", "d"), fill="right")
          %>% select(date, northern, southern))             # discard the Excel computed averages

(gt(tail(lines, 6)) 
  %>% tab_header(title="Last few days.") 
  %>% tab_source_note("Glimpse of the last few days.")
  %>% tab_options(table.font.size=9, data_row.padding = px(2)))
```
Convert that tibble into tsibble: <date> <region> <rna>
```{r infer_samples}
samples = (  # Convert lines into a table of samples
  bind_rows(
   tibble(date=lines$date, region="northern", rna=lines$northern),
   tibble(date=lines$date, region="southern", rna=lines$southern))
  %>% mutate(rna=parse_integer(rna), date=mdy(date))
  %>% drop_na() # dates with NA didn't have a sample for that region
  %>% as_tsibble(key=region, index=date)
  %>% arrange(date))

(gt(tail(samples, 6)) 
  %>% tab_header(title="Glimpse of the last few samples.")
  %>% tab_options(table.font.size=9, 
                  data_row.padding = px(2)))
```
Chart the data, twice once linear and one log.  Overlaid with a loess curve.  Why?  Because it's easy.
```{r plot_samples, fig.width = 6.5, fig.height = 7, include=TRUE}
theme_set(theme_minimal())
p_linear <- (samples %>% 
  group_by(region) %>% 
  ggplot(aes(x=date, y=rna, color=region, fill=region)) + 
  geom_point(size=1) + 
  geom_smooth(method="loess", formula= y ~ x, span = .2, alpha=.1) +
  theme(legend.position="top") +
  theme(axis.text.x = element_text(angle = 30, vjust=1, hjust=1)) +
  theme(axis.title.x=element_blank()) +
  scale_x_date(date_breaks = "2 week", date_labels="%b %d") +
  labs(subtitle="linear scale"))
p_log <- (p_linear +  scale_y_log10() + 
  theme(legend.position="none") + labs(subtitle="log scale") + geom_rug(sides="t"))
grid.arrange(top="MWRA waste water: covid rna counts", p_linear, p_log)
```
# See Also

* "SARS-CoV-2 titers in wastewater foreshadow dynamics and clinical presentation of new COVID-19 cases" [doi:10.1101/2020.06.15.20117747](https://doi.org/10.1101/2020.06.15.20117747) A preprint.
* Github repo: [bhyde/mwra_covid_samples](https://github.com/bhyde/mwra_covid_samples).
* Lastest data: [MWRA Biobot Data](http://www.mwra.com/biobot/biobotdata.htm)